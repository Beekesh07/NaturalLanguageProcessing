{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7354fd8d-f18c-4de0-89a9-86baab754f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e128ff3d-042b-4c55-8805-5270e729029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('big.txt','r',encoding='utf-8') as fd:\n",
    "    txt=fd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b178a97-da18-4204-a770-5208e039065d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I.\\nA SCANDAL IN BOHEMIA\\nI.\\nTo Sherlock Holmes she is always the woman. I have seldom heard him menti'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d47ef8f-3e89-41d4-a68f-e3a61ac7d6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579341"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e1069-67d1-406f-98ad-3e2f1ecffb50",
   "metadata": {},
   "source": [
    "#### finding unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f89850-0d56-4d26-b511-62b37ec3cdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108884\n",
      "8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\beeke\\AppData\\Local\\Temp\\ipykernel_11888\\2137623604.py:5: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  words+=re.findall('\\w+',line)\n"
     ]
    }
   ],
   "source": [
    "with open('big.txt','r',encoding='utf-8') as fd:\n",
    "    lines=fd.readlines()\n",
    "    words=[]\n",
    "    for line in lines:\n",
    "       words+=re.findall('\\w+',line) \n",
    "        \n",
    "print(len(words))\n",
    "vocab=list(set(words))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e87521c-21a9-4391-a1e4-1e0d27b2c3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "109863-108884"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc54f84-4f6d-43b5-b9b5-7255f453dd63",
   "metadata": {},
   "source": [
    "#### Probablity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f044856-a24a-4af6-a939-ff46b6193cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8831/8831 [00:17<00:00, 507.01it/s]\n"
     ]
    }
   ],
   "source": [
    "word_dict={}\n",
    "for word in tqdm.tqdm(vocab):\n",
    "    word_dict[word]=float(words.count(word)/len(words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "728a9ced-d0d7-4ac4-b5cc-90a829353b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'incredulity': 1.836817163219573e-05,\n",
       " 'stupidity': 9.184085816097865e-06,\n",
       " 'Chesterfield': 9.184085816097865e-06,\n",
       " 'backgammon': 9.184085816097865e-06,\n",
       " 'murder': 7.347268652878292e-05,\n",
       " 'ounce': 1.836817163219573e-05,\n",
       " '250': 9.184085816097865e-06,\n",
       " 'broken': 0.00011020902979317439,\n",
       " 'ours': 9.184085816097865e-06,\n",
       " 'bisulphate': 9.184085816097865e-06}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8ad0d-4873-4a65-9421-25b75d819e61",
   "metadata": {},
   "source": [
    "### Text processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a9dff3-1875-4cfa-a9a8-7d26197d1e6d",
   "metadata": {},
   "source": [
    "#### splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d4aae3-de5a-4504-b374-38e1c48727e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'beekesh'),\n",
       " ('b', 'eekesh'),\n",
       " ('be', 'ekesh'),\n",
       " ('bee', 'kesh'),\n",
       " ('beek', 'esh'),\n",
       " ('beeke', 'sh'),\n",
       " ('beekes', 'h')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(word):\n",
    "    parts=[]\n",
    "    for i in range(len(word)):\n",
    "        parts+=[(word[:i],word[i:])]\n",
    "    return parts    \n",
    "split('beekesh')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d02e3a-106a-41ab-9a03-50fcd1cad59f",
   "metadata": {},
   "source": [
    "#### deleting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0af0b372-1f39-458c-ab49-718af714ba50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eekesh', 'bekesh', 'bekesh', 'beeesh', 'beeksh', 'beekeh']\n"
     ]
    }
   ],
   "source": [
    "def delete(word):\n",
    "    output = []\n",
    "    for i, j in split(word):\n",
    "        if len(j)>1:  # Ensure there is something to delete\n",
    "            output.append(i + j[1:])\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "print(delete('beekesh'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d114343-df08-4b92-8dab-fcda4e046d80",
   "metadata": {},
   "source": [
    "#### swping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2149c41-e97c-4e4d-bd86-9c9ee9dcfff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vloe', 'love', 'lveo']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def swapping(word):\n",
    "    output=[]\n",
    "    for i,j in split(word):\n",
    "        if len(j)>1:\n",
    "            output.append(i+j[1]+j[0]+j[2:])\n",
    "    return output       \n",
    "swapping('lvoe')            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977274c-fc26-4fb0-9fda-a90b104cf7d3",
   "metadata": {},
   "source": [
    "#### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "515fb5ed-ea86-4bdd-a0bd-5a48c7a9556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lave->aabe,bave.cave,.....zave\n",
    "#lave->lave,lbve,lcve........lzve\n",
    "#.\n",
    "#."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae0f2b3-2c83-4ec7-9f2a-116254881535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aeekesh',\n",
       " 'beekesh',\n",
       " 'ceekesh',\n",
       " 'deekesh',\n",
       " 'eeekesh',\n",
       " 'feekesh',\n",
       " 'geekesh',\n",
       " 'heekesh',\n",
       " 'ieekesh',\n",
       " 'jeekesh',\n",
       " 'keekesh',\n",
       " 'leekesh',\n",
       " 'meekesh',\n",
       " 'neekesh',\n",
       " 'oeekesh',\n",
       " 'peekesh',\n",
       " 'qeekesh',\n",
       " 'reekesh',\n",
       " 'seekesh',\n",
       " 'teekesh',\n",
       " 'ueekesh',\n",
       " 'veekesh',\n",
       " 'weekesh',\n",
       " 'xeekesh',\n",
       " 'yeekesh',\n",
       " 'zeekesh',\n",
       " 'baekesh',\n",
       " 'bbekesh',\n",
       " 'bcekesh',\n",
       " 'bdekesh',\n",
       " 'beekesh',\n",
       " 'bfekesh',\n",
       " 'bgekesh',\n",
       " 'bhekesh',\n",
       " 'biekesh',\n",
       " 'bjekesh',\n",
       " 'bkekesh',\n",
       " 'blekesh',\n",
       " 'bmekesh',\n",
       " 'bnekesh',\n",
       " 'boekesh',\n",
       " 'bpekesh',\n",
       " 'bqekesh',\n",
       " 'brekesh',\n",
       " 'bsekesh',\n",
       " 'btekesh',\n",
       " 'buekesh',\n",
       " 'bvekesh',\n",
       " 'bwekesh',\n",
       " 'bxekesh',\n",
       " 'byekesh',\n",
       " 'bzekesh',\n",
       " 'beakesh',\n",
       " 'bebkesh',\n",
       " 'beckesh',\n",
       " 'bedkesh',\n",
       " 'beekesh',\n",
       " 'befkesh',\n",
       " 'begkesh',\n",
       " 'behkesh',\n",
       " 'beikesh',\n",
       " 'bejkesh',\n",
       " 'bekkesh',\n",
       " 'belkesh',\n",
       " 'bemkesh',\n",
       " 'benkesh',\n",
       " 'beokesh',\n",
       " 'bepkesh',\n",
       " 'beqkesh',\n",
       " 'berkesh',\n",
       " 'beskesh',\n",
       " 'betkesh',\n",
       " 'beukesh',\n",
       " 'bevkesh',\n",
       " 'bewkesh',\n",
       " 'bexkesh',\n",
       " 'beykesh',\n",
       " 'bezkesh',\n",
       " 'beeaesh',\n",
       " 'beebesh',\n",
       " 'beecesh',\n",
       " 'beedesh',\n",
       " 'beeeesh',\n",
       " 'beefesh',\n",
       " 'beegesh',\n",
       " 'beehesh',\n",
       " 'beeiesh',\n",
       " 'beejesh',\n",
       " 'beekesh',\n",
       " 'beelesh',\n",
       " 'beemesh',\n",
       " 'beenesh',\n",
       " 'beeoesh',\n",
       " 'beepesh',\n",
       " 'beeqesh',\n",
       " 'beeresh',\n",
       " 'beesesh',\n",
       " 'beetesh',\n",
       " 'beeuesh',\n",
       " 'beevesh',\n",
       " 'beewesh',\n",
       " 'beexesh',\n",
       " 'beeyesh',\n",
       " 'beezesh',\n",
       " 'beekash',\n",
       " 'beekbsh',\n",
       " 'beekcsh',\n",
       " 'beekdsh',\n",
       " 'beekesh',\n",
       " 'beekfsh',\n",
       " 'beekgsh',\n",
       " 'beekhsh',\n",
       " 'beekish',\n",
       " 'beekjsh',\n",
       " 'beekksh',\n",
       " 'beeklsh',\n",
       " 'beekmsh',\n",
       " 'beeknsh',\n",
       " 'beekosh',\n",
       " 'beekpsh',\n",
       " 'beekqsh',\n",
       " 'beekrsh',\n",
       " 'beekssh',\n",
       " 'beektsh',\n",
       " 'beekush',\n",
       " 'beekvsh',\n",
       " 'beekwsh',\n",
       " 'beekxsh',\n",
       " 'beekysh',\n",
       " 'beekzsh',\n",
       " 'beekeah',\n",
       " 'beekebh',\n",
       " 'beekech',\n",
       " 'beekedh',\n",
       " 'beekeeh',\n",
       " 'beekefh',\n",
       " 'beekegh',\n",
       " 'beekehh',\n",
       " 'beekeih',\n",
       " 'beekejh',\n",
       " 'beekekh',\n",
       " 'beekelh',\n",
       " 'beekemh',\n",
       " 'beekenh',\n",
       " 'beekeoh',\n",
       " 'beekeph',\n",
       " 'beekeqh',\n",
       " 'beekerh',\n",
       " 'beekesh',\n",
       " 'beeketh',\n",
       " 'beekeuh',\n",
       " 'beekevh',\n",
       " 'beekewh',\n",
       " 'beekexh',\n",
       " 'beekeyh',\n",
       " 'beekezh',\n",
       " 'beekesa',\n",
       " 'beekesb',\n",
       " 'beekesc',\n",
       " 'beekesd',\n",
       " 'beekese',\n",
       " 'beekesf',\n",
       " 'beekesg',\n",
       " 'beekesh',\n",
       " 'beekesi',\n",
       " 'beekesj',\n",
       " 'beekesk',\n",
       " 'beekesl',\n",
       " 'beekesm',\n",
       " 'beekesn',\n",
       " 'beekeso',\n",
       " 'beekesp',\n",
       " 'beekesq',\n",
       " 'beekesr',\n",
       " 'beekess',\n",
       " 'beekest',\n",
       " 'beekesu',\n",
       " 'beekesv',\n",
       " 'beekesw',\n",
       " 'beekesx',\n",
       " 'beekesy',\n",
       " 'beekesz']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace(word):\n",
    "    output=[]\n",
    "    characters='abcdefghijklmnopqrstuvwxyz'\n",
    "    for i,j in split(word):\n",
    "        for char in characters:\n",
    "            output.append(i+char+j[1:])\n",
    "    return output\n",
    "replace('beekesh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a5ca1-aec0-46b8-ae26-b42fb8dc634a",
   "metadata": {},
   "source": [
    "#### Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25984a9c-6aed-4c3f-94a3-793167de7f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alove',\n",
       " 'blove',\n",
       " 'clove',\n",
       " 'dlove',\n",
       " 'elove',\n",
       " 'flove',\n",
       " 'glove',\n",
       " 'hlove',\n",
       " 'ilove',\n",
       " 'jlove',\n",
       " 'klove',\n",
       " 'llove',\n",
       " 'mlove',\n",
       " 'nlove',\n",
       " 'olove',\n",
       " 'plove',\n",
       " 'qlove',\n",
       " 'rlove',\n",
       " 'slove',\n",
       " 'tlove',\n",
       " 'ulove',\n",
       " 'vlove',\n",
       " 'wlove',\n",
       " 'xlove',\n",
       " 'ylove',\n",
       " 'zlove',\n",
       " 'laove',\n",
       " 'lbove',\n",
       " 'lcove',\n",
       " 'ldove',\n",
       " 'leove',\n",
       " 'lfove',\n",
       " 'lgove',\n",
       " 'lhove',\n",
       " 'liove',\n",
       " 'ljove',\n",
       " 'lkove',\n",
       " 'llove',\n",
       " 'lmove',\n",
       " 'lnove',\n",
       " 'loove',\n",
       " 'lpove',\n",
       " 'lqove',\n",
       " 'lrove',\n",
       " 'lsove',\n",
       " 'ltove',\n",
       " 'luove',\n",
       " 'lvove',\n",
       " 'lwove',\n",
       " 'lxove',\n",
       " 'lyove',\n",
       " 'lzove',\n",
       " 'loave',\n",
       " 'lobve',\n",
       " 'locve',\n",
       " 'lodve',\n",
       " 'loeve',\n",
       " 'lofve',\n",
       " 'logve',\n",
       " 'lohve',\n",
       " 'loive',\n",
       " 'lojve',\n",
       " 'lokve',\n",
       " 'lolve',\n",
       " 'lomve',\n",
       " 'lonve',\n",
       " 'loove',\n",
       " 'lopve',\n",
       " 'loqve',\n",
       " 'lorve',\n",
       " 'losve',\n",
       " 'lotve',\n",
       " 'louve',\n",
       " 'lovve',\n",
       " 'lowve',\n",
       " 'loxve',\n",
       " 'loyve',\n",
       " 'lozve',\n",
       " 'lovae',\n",
       " 'lovbe',\n",
       " 'lovce',\n",
       " 'lovde',\n",
       " 'lovee',\n",
       " 'lovfe',\n",
       " 'lovge',\n",
       " 'lovhe',\n",
       " 'lovie',\n",
       " 'lovje',\n",
       " 'lovke',\n",
       " 'lovle',\n",
       " 'lovme',\n",
       " 'lovne',\n",
       " 'lovoe',\n",
       " 'lovpe',\n",
       " 'lovqe',\n",
       " 'lovre',\n",
       " 'lovse',\n",
       " 'lovte',\n",
       " 'lovue',\n",
       " 'lovve',\n",
       " 'lovwe',\n",
       " 'lovxe',\n",
       " 'lovye',\n",
       " 'lovze']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters='abcdefghijklmnopqrstuvwxyz'\n",
    "def insert(word):\n",
    "    output=[]\n",
    "    for i ,j in split(word):\n",
    "        for char in characters:\n",
    "            output.append(i+char+j)\n",
    "    return output\n",
    "insert('love')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5868d86-a53e-429b-95b3-8445c3264e48",
   "metadata": {},
   "source": [
    "#### combining possible words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eba3d4c6-0e73-4781-8448-ea684445fae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aleave',\n",
       " 'bleave',\n",
       " 'cleave',\n",
       " 'dleave',\n",
       " 'eleave',\n",
       " 'fleave',\n",
       " 'gleave',\n",
       " 'hleave',\n",
       " 'ileave',\n",
       " 'jleave',\n",
       " 'kleave',\n",
       " 'lleave',\n",
       " 'mleave',\n",
       " 'nleave',\n",
       " 'oleave',\n",
       " 'pleave',\n",
       " 'qleave',\n",
       " 'rleave',\n",
       " 'sleave',\n",
       " 'tleave',\n",
       " 'uleave',\n",
       " 'vleave',\n",
       " 'wleave',\n",
       " 'xleave',\n",
       " 'yleave',\n",
       " 'zleave',\n",
       " 'laeave',\n",
       " 'lbeave',\n",
       " 'lceave',\n",
       " 'ldeave',\n",
       " 'leeave',\n",
       " 'lfeave',\n",
       " 'lgeave',\n",
       " 'lheave',\n",
       " 'lieave',\n",
       " 'ljeave',\n",
       " 'lkeave',\n",
       " 'lleave',\n",
       " 'lmeave',\n",
       " 'lneave',\n",
       " 'loeave',\n",
       " 'lpeave',\n",
       " 'lqeave',\n",
       " 'lreave',\n",
       " 'lseave',\n",
       " 'lteave',\n",
       " 'lueave',\n",
       " 'lveave',\n",
       " 'lweave',\n",
       " 'lxeave',\n",
       " 'lyeave',\n",
       " 'lzeave',\n",
       " 'leaave',\n",
       " 'lebave',\n",
       " 'lecave',\n",
       " 'ledave',\n",
       " 'leeave',\n",
       " 'lefave',\n",
       " 'legave',\n",
       " 'lehave',\n",
       " 'leiave',\n",
       " 'lejave',\n",
       " 'lekave',\n",
       " 'lelave',\n",
       " 'lemave',\n",
       " 'lenave',\n",
       " 'leoave',\n",
       " 'lepave',\n",
       " 'leqave',\n",
       " 'lerave',\n",
       " 'lesave',\n",
       " 'letave',\n",
       " 'leuave',\n",
       " 'levave',\n",
       " 'lewave',\n",
       " 'lexave',\n",
       " 'leyave',\n",
       " 'lezave',\n",
       " 'leaave',\n",
       " 'leabve',\n",
       " 'leacve',\n",
       " 'leadve',\n",
       " 'leaeve',\n",
       " 'leafve',\n",
       " 'leagve',\n",
       " 'leahve',\n",
       " 'leaive',\n",
       " 'leajve',\n",
       " 'leakve',\n",
       " 'lealve',\n",
       " 'leamve',\n",
       " 'leanve',\n",
       " 'leaove',\n",
       " 'leapve',\n",
       " 'leaqve',\n",
       " 'learve',\n",
       " 'leasve',\n",
       " 'leatve',\n",
       " 'leauve',\n",
       " 'leavve',\n",
       " 'leawve',\n",
       " 'leaxve',\n",
       " 'leayve',\n",
       " 'leazve',\n",
       " 'leavae',\n",
       " 'leavbe',\n",
       " 'leavce',\n",
       " 'leavde',\n",
       " 'leavee',\n",
       " 'leavfe',\n",
       " 'leavge',\n",
       " 'leavhe',\n",
       " 'leavie',\n",
       " 'leavje',\n",
       " 'leavke',\n",
       " 'leavle',\n",
       " 'leavme',\n",
       " 'leavne',\n",
       " 'leavoe',\n",
       " 'leavpe',\n",
       " 'leavqe',\n",
       " 'leavre',\n",
       " 'leavse',\n",
       " 'leavte',\n",
       " 'leavue',\n",
       " 'leavve',\n",
       " 'leavwe',\n",
       " 'leavxe',\n",
       " 'leavye',\n",
       " 'leavze',\n",
       " 'aeave',\n",
       " 'beave',\n",
       " 'ceave',\n",
       " 'deave',\n",
       " 'eeave',\n",
       " 'feave',\n",
       " 'geave',\n",
       " 'heave',\n",
       " 'ieave',\n",
       " 'jeave',\n",
       " 'keave',\n",
       " 'leave',\n",
       " 'meave',\n",
       " 'neave',\n",
       " 'oeave',\n",
       " 'peave',\n",
       " 'qeave',\n",
       " 'reave',\n",
       " 'seave',\n",
       " 'teave',\n",
       " 'ueave',\n",
       " 'veave',\n",
       " 'weave',\n",
       " 'xeave',\n",
       " 'yeave',\n",
       " 'zeave',\n",
       " 'laave',\n",
       " 'lbave',\n",
       " 'lcave',\n",
       " 'ldave',\n",
       " 'leave',\n",
       " 'lfave',\n",
       " 'lgave',\n",
       " 'lhave',\n",
       " 'liave',\n",
       " 'ljave',\n",
       " 'lkave',\n",
       " 'llave',\n",
       " 'lmave',\n",
       " 'lnave',\n",
       " 'loave',\n",
       " 'lpave',\n",
       " 'lqave',\n",
       " 'lrave',\n",
       " 'lsave',\n",
       " 'ltave',\n",
       " 'luave',\n",
       " 'lvave',\n",
       " 'lwave',\n",
       " 'lxave',\n",
       " 'lyave',\n",
       " 'lzave',\n",
       " 'leave',\n",
       " 'lebve',\n",
       " 'lecve',\n",
       " 'ledve',\n",
       " 'leeve',\n",
       " 'lefve',\n",
       " 'legve',\n",
       " 'lehve',\n",
       " 'leive',\n",
       " 'lejve',\n",
       " 'lekve',\n",
       " 'lelve',\n",
       " 'lemve',\n",
       " 'lenve',\n",
       " 'leove',\n",
       " 'lepve',\n",
       " 'leqve',\n",
       " 'lerve',\n",
       " 'lesve',\n",
       " 'letve',\n",
       " 'leuve',\n",
       " 'levve',\n",
       " 'lewve',\n",
       " 'lexve',\n",
       " 'leyve',\n",
       " 'lezve',\n",
       " 'leaae',\n",
       " 'leabe',\n",
       " 'leace',\n",
       " 'leade',\n",
       " 'leaee',\n",
       " 'leafe',\n",
       " 'leage',\n",
       " 'leahe',\n",
       " 'leaie',\n",
       " 'leaje',\n",
       " 'leake',\n",
       " 'leale',\n",
       " 'leame',\n",
       " 'leane',\n",
       " 'leaoe',\n",
       " 'leape',\n",
       " 'leaqe',\n",
       " 'leare',\n",
       " 'lease',\n",
       " 'leate',\n",
       " 'leaue',\n",
       " 'leave',\n",
       " 'leawe',\n",
       " 'leaxe',\n",
       " 'leaye',\n",
       " 'leaze',\n",
       " 'leava',\n",
       " 'leavb',\n",
       " 'leavc',\n",
       " 'leavd',\n",
       " 'leave',\n",
       " 'leavf',\n",
       " 'leavg',\n",
       " 'leavh',\n",
       " 'leavi',\n",
       " 'leavj',\n",
       " 'leavk',\n",
       " 'leavl',\n",
       " 'leavm',\n",
       " 'leavn',\n",
       " 'leavo',\n",
       " 'leavp',\n",
       " 'leavq',\n",
       " 'leavr',\n",
       " 'leavs',\n",
       " 'leavt',\n",
       " 'leavu',\n",
       " 'leavv',\n",
       " 'leavw',\n",
       " 'leavx',\n",
       " 'leavy',\n",
       " 'leavz',\n",
       " 'eave',\n",
       " 'lave',\n",
       " 'leve',\n",
       " 'leae',\n",
       " 'elave',\n",
       " 'laeve',\n",
       " 'levae',\n",
       " 'leaev']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edit(word):\n",
    "    return insert(word)+replace(word)+delete(word)+swapping(word)\n",
    "edit('leave')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9171e-53f5-438d-882e-bae9f66dd88e",
   "metadata": {},
   "source": [
    "#### Predicting level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba8c41eb-4e1e-4344-8d2c-0b52c5c1da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=[]\n",
    "def spellChecker(word,count=5):\n",
    "    suggested_word=edit(word)\n",
    "   \n",
    "    for wrd in suggested_word:\n",
    "        if wrd in word_dict.keys() :\n",
    "            outputs.append([wrd,word_dict[wrd]])\n",
    "    return list(pd.DataFrame(data=outputs,columns=['word','prob']).sort_values(by='prob',ascending=True)['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a42e54c0-6226-4f33-b3eb-5c79cb6c9f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leave', 'leave']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellChecker('laeve',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534e1e7-2640-4b21-b566-c75c59cf0b0a",
   "metadata": {},
   "source": [
    "#### Predicting level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "865ce623-da8b-4d7a-bfc4-a51ab4fd2404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit2(word):\n",
    "    output=[]\n",
    "    suggested_words=edit(word)\n",
    "    for e1 in edit(word):\n",
    "        suggested_words+=edit(e1)\n",
    "        suggested_words=list(suggested_words)\n",
    "        for wrd in  word_dict.keys():\n",
    "            output.append(word_dict[wrd])\n",
    "    return list(pd.DataFrame(data=outputs,columns=['word','prob']).sort_values(by='prob',ascending=True)['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db0ff5be-9372-4b95-84b3-49615853ca98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leave', 'leave']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit2('lave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70547ab8-a527-4fce-97ae-cf26fa0f7cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
